{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKENeWEEwKIb"
      },
      "source": [
        "Model interpretability - Making your model confesses: Saliency maps\n",
        "===================================================================\n",
        "\n",
        "This notebooks contains an example to use AllenNLP to interpret a model constructed using HuggingFace transormers using saliency maps. First, let's install the following libraries:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers allennlp eli5 --quiet\n",
        "%pip install -U google-cloud-storage==1.40.0 --quiet"
      ],
      "metadata": {
        "id": "PSQbvcjYdbis",
        "outputId": "a83f7ed1-30fd-4bd5-899f-40cfddd950ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.2 MB 8.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 719 kB 60.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 216 kB 57.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 45.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 592 kB 51.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 36.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 47.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 248 kB 14.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 46.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 880 kB 63.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 32.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 50.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 69.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 66.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 64.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 58.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 55.0 MB/s \n",
            "\u001b[?25h  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 104 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.6 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 1.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0uIrAVo4leg"
      },
      "source": [
        "Loading NLP HuggingFace models into AllenNLP framework\n",
        "-------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXgQvCX2wKJi"
      },
      "source": [
        "AllenNLP is a general deep learning framework for NLP, established by the world-famous Allen Institute for AI Lab. Its team envisions language-centered AI that equitably serves humanity. As a small team, researchers and engineers work closely together to publish impactful research and identify common investments that would benefit the field as a whole."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we will use nlptown/bert-base-multilingual-uncased-sentiment. This is a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5).\n",
        "\n",
        "The model can be used directly as a sentiment analysis model for product reviews in any of the six languages, or further finetuned on related sentiment analysis tasks. To keep the example small, we won't do any fine-tuning with our own data in this opportunity."
      ],
      "metadata": {
        "id": "yBjRxCOzHMlT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dxqTaKSc4leh"
      },
      "outputs": [],
      "source": [
        "model_uri = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
        "model_name = model_uri"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "classifier = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "71dMYC1jrka6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyidNud34leh"
      },
      "source": [
        "## Loading the model using AllenNLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnhc4x7y4leh"
      },
      "source": [
        "AllenNLP allows a declarative way of loading models. The entire architecture can be specified using the language JSONNET. This allows even faster iteration for trying new combination of different architectures as it only takes changing the relevant part in the declarative JSON. The following JSONNET (which is indicated using the type Params but you can do exactly the same saving the json structure in a JSONNET file) is the very same equivalent to the model we used before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3ZQPaNL2s23z"
      },
      "outputs": [],
      "source": [
        "from allennlp.common import Params\n",
        "from allennlp.data.dataset_readers import DatasetReader\n",
        "\n",
        "params = Params({\n",
        "      \"type\": \"text_classification_json\",\n",
        "      \"tokenizer\": {\n",
        "          \"type\": \"pretrained_transformer\",\n",
        "          \"model_name\": model_name,\n",
        "      },\n",
        "      \"token_indexers\": {\n",
        "          \"tokens\": {\n",
        "              \"type\": \"pretrained_transformer\",\n",
        "              \"model_name\": model_name,\n",
        "          }\n",
        "      }\n",
        "})\n",
        "\n",
        "dataset_reader = DatasetReader.from_params(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YJS_5MUHT6ae",
        "outputId": "579f66dc-3567-4c3b-9b82-ab0c2ce792a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from allennlp.common import Params\n",
        "from allennlp.models import Model\n",
        "\n",
        "params = Params({\n",
        "    \"type\": \"basic_classifier\",\n",
        "    \"vocab\": {\n",
        "        \"type\": \"from_pretrained_transformer\",\n",
        "        \"model_name\": model_name,\n",
        "    },\n",
        "    \"text_field_embedder\": {\n",
        "        \"type\": \"basic\",\n",
        "        \"token_embedders\": {\n",
        "            \"tokens\": {\n",
        "                \"type\": \"pretrained_transformer\",\n",
        "                \"model_name\": model_name\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"seq2vec_encoder\": {\n",
        "        \"type\": \"bert_pooler\",\n",
        "        \"pretrained_model\": model_name\n",
        "    },\n",
        "    \"dropout\": 0.1,\n",
        "    \"num_labels\": 5,\n",
        "});\n",
        "\n",
        "model = Model.from_params(params)\n",
        "model._classification_layer.weight = classifier.classifier.weight\n",
        "model._classification_layer.bias = classifier.classifier.bias\n",
        "_ = model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating our predictor based on the dataset reader and the model:"
      ],
      "metadata": {
        "id": "ytP4MJczIa9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from allennlp.predictors import TextClassifierPredictor\n",
        "\n",
        "predictor = TextClassifierPredictor(model, dataset_reader)"
      ],
      "metadata": {
        "id": "oyA6cR5rIJ-D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kB6qBzO4lem"
      },
      "source": [
        "Interpreting predictions using AllenNLP and Saliency Maps\n",
        "---------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {\n",
        "    \"1-stars\": 0,\n",
        "    \"2-stars\": 1,\n",
        "    \"3-stars\": 2,\n",
        "    \"4-stars\": 3,\n",
        "    \"5-stars\": 4\n",
        "}"
      ],
      "metadata": {
        "id": "cC0zrXJKJc_k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xKd49lBLd0g"
      },
      "source": [
        "Let's consider the following example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "gm4mMJqALd0h"
      },
      "outputs": [],
      "source": [
        "sample_text = \"Not buying it any sooner! Other brands do a much better job\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "YAVt2O_CLd0h"
      },
      "outputs": [],
      "source": [
        "inputs = {\"sentence\": sample_text }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Integrated Gradients"
      ],
      "metadata": {
        "id": "c_4kAITAIE5i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "NTX6HgF6sXrs"
      },
      "outputs": [],
      "source": [
        "from allennlp.interpret.saliency_interpreters import IntegratedGradient, SmoothGradient\n",
        "\n",
        "interpreter = IntegratedGradient(predictor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the gradients:"
      ],
      "metadata": {
        "id": "BI7i9c7bL0Ow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "j_i_OjI_edIS"
      },
      "outputs": [],
      "source": [
        "inputs = {\"sentence\": sample_text }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_00Ya8ZelBk",
        "outputId": "24213fa0-834b-473e-8ac2-2a770e130255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "interpretation = interpreter.saliency_interpret_from_json(inputs)\n",
        "outputs = predictor.predict(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qMHb-1zJJtC",
        "outputId": "11db3a2b-239f-40a5-8343-0947528f9ca0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['logits', 'probs', 'token_ids', 'label', 'tokens'])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grads = np.array(interpretation['instance_1']['grad_input_1'])\n",
        "probs = np.array(outputs['probs'])"
      ],
      "metadata": {
        "id": "ECjJ9_FOLDVr"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gF--Q8v4len"
      },
      "source": [
        "Let's plot the results:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from eli5.formatters import format_as_html\n",
        "from eli5_allennlp import get_explanation_from_grads"
      ],
      "metadata": {
        "id": "VVzMp5Ycnyjk"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expl = get_explanation_from_grads(estimator_name=\"transformer\",\n",
        "                                  estimator_description=\"NLP transformer explanation\",\n",
        "                                  text=sample_text,\n",
        "                                  tokens=outputs['tokens'],\n",
        "                                  grads=grads,\n",
        "                                  probas=probs,\n",
        "                                  labels=list(labels.keys()))"
      ],
      "metadata": {
        "id": "46cRql8uoG7Q"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HTML(format_as_html(expl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "jHNWCxoEoLT5",
        "outputId": "fd754760-4e5e-4037-e713-816f858bcefe"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "        <pre>NLP transformer explanation</pre>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1-stars\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.498</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.000\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.303\">No</span><span style=\"background-color: hsl(120, 100.00%, 98.36%); opacity: 0.80\" title=\"0.003\">t</span><span style=\"background-color: hsl(120, 100.00%, 81.36%); opacity: 0.87\" title=\"0.102\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.76%); opacity: 0.87\" title=\"0.099\">buyin</span><span style=\"opacity: 0.80\">g</span><span style=\"background-color: hsl(120, 100.00%, 93.02%); opacity: 0.82\" title=\"0.025\"> i</span><span style=\"opacity: 0.80\">t</span><span style=\"background-color: hsl(120, 100.00%, 97.49%); opacity: 0.80\" title=\"0.006\"> an</span><span style=\"opacity: 0.80\">y</span><span style=\"background-color: hsl(120, 100.00%, 94.76%); opacity: 0.81\" title=\"0.017\"> soo</span><span style=\"background-color: hsl(120, 100.00%, 95.22%); opacity: 0.81\" title=\"0.015\">ne</span><span style=\"opacity: 0.80\">r</span><span style=\"background-color: hsl(120, 100.00%, 92.29%); opacity: 0.82\" title=\"0.029\">!</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.28%); opacity: 0.83\" title=\"0.040\">Other</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.59%); opacity: 0.81\" title=\"0.022\">brands</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.69%); opacity: 0.83\" title=\"0.044\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.39%); opacity: 0.81\" title=\"0.018\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.15%); opacity: 0.82\" title=\"0.030\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.43%); opacity: 0.92\" title=\"0.178\">better</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.44%); opacity: 0.88\" title=\"0.125\">job</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expl = get_explanation_from_grads(estimator_name=\"transformer\",\n",
        "                                  estimator_description=\"NLP transformer explanation\",\n",
        "                                  text=sample_text,\n",
        "                                  tokens=outputs['tokens'],\n",
        "                                  grads=grads,\n",
        "                                  probas=probs,\n",
        "                                  labels=list(labels.keys()),\n",
        "                                  force_weights=True)"
      ],
      "metadata": {
        "id": "ooL6c2HMoIyD"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HTML(format_as_html(expl, force_weights=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "ogZlHtnpoK3b",
        "outputId": "768f648f-4d53-499b-98f1-5b9100f6a6c9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "        <pre>NLP transformer explanation</pre>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1-stars\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.498</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
              "                    Weight<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.17%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.003\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        [CLS]\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.299\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        not\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 90.81%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.099\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        buying\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.48%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.025\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        it\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 98.74%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.006\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        any\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.36%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.017\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        soon\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.59%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.015\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ##er\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.11%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.029\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        !\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.10%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.040\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        other\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.77%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.022\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        brands\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.81%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.044\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        do\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.18%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.018\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        a\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.05%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.030\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        much\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.11%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.178\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        better\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 89.14%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.125\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        job\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.16%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.052\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        [SEP]\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.303\">No</span><span style=\"background-color: hsl(120, 100.00%, 98.36%); opacity: 0.80\" title=\"0.003\">t</span><span style=\"background-color: hsl(120, 100.00%, 81.36%); opacity: 0.87\" title=\"0.102\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.76%); opacity: 0.87\" title=\"0.099\">buyin</span><span style=\"opacity: 0.80\">g</span><span style=\"background-color: hsl(120, 100.00%, 93.02%); opacity: 0.82\" title=\"0.025\"> i</span><span style=\"opacity: 0.80\">t</span><span style=\"background-color: hsl(120, 100.00%, 97.49%); opacity: 0.80\" title=\"0.006\"> an</span><span style=\"opacity: 0.80\">y</span><span style=\"background-color: hsl(120, 100.00%, 94.76%); opacity: 0.81\" title=\"0.017\"> soo</span><span style=\"background-color: hsl(120, 100.00%, 95.22%); opacity: 0.81\" title=\"0.015\">ne</span><span style=\"opacity: 0.80\">r</span><span style=\"background-color: hsl(120, 100.00%, 92.29%); opacity: 0.82\" title=\"0.029\">!</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.28%); opacity: 0.83\" title=\"0.040\">Other</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.59%); opacity: 0.81\" title=\"0.022\">brands</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.69%); opacity: 0.83\" title=\"0.044\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.39%); opacity: 0.81\" title=\"0.018\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.15%); opacity: 0.82\" title=\"0.030\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.43%); opacity: 0.92\" title=\"0.178\">better</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.44%); opacity: 0.88\" title=\"0.125\">job</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Smooth Gradients"
      ],
      "metadata": {
        "id": "uwuCjtqiLd0N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "VtTZB5HZLd0f"
      },
      "outputs": [],
      "source": [
        "from allennlp.interpret.saliency_interpreters import IntegratedGradient, SmoothGradient\n",
        "\n",
        "interpreter = SmoothGradient(predictor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM7eiwX3Ld0h"
      },
      "source": [
        "Calculate the gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f7b46b-4a19-4390-9875-857e02111537",
        "id": "S__pwnSPLd0i"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "interpretation = interpreter.saliency_interpret_from_json(inputs)\n",
        "outputs = predictor.predict(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba1037f-d5d3-4b2d-8f6d-8335868cfef2",
        "id": "BxBmBG1wLd0i"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['logits', 'probs', 'token_ids', 'label', 'tokens'])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grads = np.array(interpretation['instance_1']['grad_input_1'])\n",
        "probs = np.array(outputs['probs'])"
      ],
      "metadata": {
        "id": "RwPq4KDrLd0j"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8BpcTAZLd0j"
      },
      "source": [
        "Let's plot the results:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from eli5.formatters import format_as_html\n",
        "from eli5_allennlp import get_explanation_from_grads"
      ],
      "metadata": {
        "id": "P4Vq4kSCLd0j"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expl = get_explanation_from_grads(estimator_name=\"transformer\",\n",
        "                                  estimator_description=\"NLP transformer explanation\",\n",
        "                                  text=sample_text,\n",
        "                                  tokens=outputs['tokens'],\n",
        "                                  grads=grads,\n",
        "                                  probas=probs,\n",
        "                                  labels=list(labels.keys()))"
      ],
      "metadata": {
        "id": "go7MHkV8Ld0k"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HTML(format_as_html(expl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d67e802c-e4c6-4d80-d4cc-655a33db3b62",
        "id": "RvnM8IviLd0k"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "        <pre>NLP transformer explanation</pre>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1-stars\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.498</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.000\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 86.04%); opacity: 0.84\" title=\"0.057\">No</span><span style=\"background-color: hsl(120, 100.00%, 91.41%); opacity: 0.82\" title=\"0.028\">t</span><span style=\"background-color: hsl(120, 100.00%, 86.04%); opacity: 0.84\" title=\"0.057\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.41%); opacity: 0.82\" title=\"0.028\">buyin</span><span style=\"opacity: 0.80\">g</span><span style=\"background-color: hsl(120, 100.00%, 96.74%); opacity: 0.81\" title=\"0.007\"> i</span><span style=\"opacity: 0.80\">t</span><span style=\"background-color: hsl(120, 100.00%, 86.04%); opacity: 0.84\" title=\"0.057\"> an</span><span style=\"opacity: 0.80\">y</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.255\"> soo</span><span style=\"background-color: hsl(120, 100.00%, 83.68%); opacity: 0.86\" title=\"0.071\">ne</span><span style=\"opacity: 0.80\">r! </span><span style=\"background-color: hsl(120, 100.00%, 82.56%); opacity: 0.86\" title=\"0.078\">Other</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.04%); opacity: 0.84\" title=\"0.057\">brands</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.71%); opacity: 0.81\" title=\"0.014\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.56%); opacity: 0.86\" title=\"0.078\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.41%); opacity: 0.82\" title=\"0.028\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.66%); opacity: 0.92\" title=\"0.156\">better</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.41%); opacity: 0.82\" title=\"0.028\">job</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expl = get_explanation_from_grads(estimator_name=\"transformer\",\n",
        "                                  estimator_description=\"NLP transformer explanation\",\n",
        "                                  text=sample_text,\n",
        "                                  tokens=outputs['tokens'],\n",
        "                                  grads=grads,\n",
        "                                  probas=probs,\n",
        "                                  labels=list(labels.keys()),\n",
        "                                  force_weights=True)"
      ],
      "metadata": {
        "id": "Y7CedB0ULd0k"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HTML(format_as_html(expl, force_weights=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "287e6ffa-9a9e-4bc2-f9ea-5df9a54dc214",
        "id": "WrEGL8F7Ld0l"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "        <pre>NLP transformer explanation</pre>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1-stars\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.498</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
              "                    Weight<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.028\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        [CLS]\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.028\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        not\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.028\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        buying\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 98.37%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.007\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        it\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.02%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.057\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        any\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.255\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        soon\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.84%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.071\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ##er\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.000\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        !\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.28%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.078\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        other\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.02%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.057\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        brands\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.36%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.014\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        do\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.28%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.078\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        a\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.028\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        much\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.83%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.156\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        better\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.028\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        job\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.085\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        [SEP]\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 86.04%); opacity: 0.84\" title=\"0.057\">No</span><span style=\"background-color: hsl(120, 100.00%, 91.41%); opacity: 0.82\" title=\"0.028\">t</span><span style=\"background-color: hsl(120, 100.00%, 86.04%); opacity: 0.84\" title=\"0.057\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.41%); opacity: 0.82\" title=\"0.028\">buyin</span><span style=\"opacity: 0.80\">g</span><span style=\"background-color: hsl(120, 100.00%, 96.74%); opacity: 0.81\" title=\"0.007\"> i</span><span style=\"opacity: 0.80\">t</span><span style=\"background-color: hsl(120, 100.00%, 86.04%); opacity: 0.84\" title=\"0.057\"> an</span><span style=\"opacity: 0.80\">y</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.255\"> soo</span><span style=\"background-color: hsl(120, 100.00%, 83.68%); opacity: 0.86\" title=\"0.071\">ne</span><span style=\"opacity: 0.80\">r! </span><span style=\"background-color: hsl(120, 100.00%, 82.56%); opacity: 0.86\" title=\"0.078\">Other</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.04%); opacity: 0.84\" title=\"0.057\">brands</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.71%); opacity: 0.81\" title=\"0.014\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.56%); opacity: 0.86\" title=\"0.078\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.41%); opacity: 0.82\" title=\"0.028\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.66%); opacity: 0.92\" title=\"0.156\">better</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.41%); opacity: 0.82\" title=\"0.028\">job</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "allennlp_interpret.ipynb",
      "provenance": []
    },
    "kernel_info": {
      "name": "nlp-py38"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - PyTorch",
      "language": "python",
      "name": "azureml_py38_pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}